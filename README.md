# About bcltofrag

This repository contains a pipeline to process next-generation sequencing (NGS) data generated by Illumina sequencers. The workflow converts Illumina run folders (BCL format) into fragmentomic tables and plots using the FinaleToolkit Python package, specifically the `frag_length_bins()` and `end_motifs()` functions.

To runthe pipeline, the following files must be present in each Illumina run folder:

- `RunInfo.xml`
- `SampleSheet.csv`

> **_NOTE:_** This pipeline is not fully automated. It was developed to explore the intermediate outputs as part of the final project for the MSc in Bioinformatics and Biostatistics from the Universitat Oberta de Catalunya (UOC).

The Jupyter notebook *notebook_analysis_fragmentomics.ipynb* shows the implementation of FinaleToolkit in Python, including the exploration steps of the downstream data, and the code used to generate the figures in the report.

# Installation

1. Copy the Illumina run folder into `./data/runs`.

2. Clone the repository in the project root directory (`./`)

3. Intall conda environment from the provided YAML file and register it as a Python kernel.

```bash
conda env create --name <env_name> --file environment.yaml

conda activate <env_name>

python -m ipykernel install --user --name <env_name> --display-name "Python (<env_name>)"
```

> **_NOTE:_** This pipeline processes large sequencing datasets and generates substantial intermediate and output files (including BCL files, FASTQ files, BAM files, and QC outputs). It is therefore advised to place the project directory on a disk or filesystem with sufficient available storage.
As a reference, processing a dataset of 52 samples sequenced using a targeted panel covering 13 exons required approximately 720 GB of disk space, including raw Illumina run data and downstream outputs.

# Usage

1. Download reference files for alignments.

```bash
# create containing folder within ../data
mkdir -p ../data/reference

# update path to reference of interest
wget -P ../data/reference https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz

wget -P ../data/reference https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.2bit # .2bit for end_motifs

# unzip file
gunzip ../data/reference/hg38.fa.gz
```

2. Run **snakefile_bcl2fastq.py**.

```bash
bsub -o logs_hpc/out.txt -e logs_hpc/err.txt -q bio -n 8 -W 1400 -M 64000 -hl -R 'rusage[mem=64000]' snakemake -s snakefile_bcl2fastq.py --cores 8
```

3. Run **fastqc.sh** and explore sequencing quality.

```bash
bsub -o logs_hpc/out_fastqc.txt -e logs_hpc/err_fastqc.txt -q bio -n 1 -W 1400 -M 64000 -hl -R 'rusage[mem=10000]' bash ./fastqc.sh
```

5. Generate reference index files prior alignment.

*Note: since bwa-mem requires high memory usage, I request 64GB on the LSF. Ref: https://github.com/bwa-mem2/bwa-mem2/issues/267.*

```bash
bsub -o logs_hpc/out_bwa_index.txt -e logs_hpc/err_bwa_index.txt -q bio -n 1 -W 1400 -M 64000 -hl -R 'rusage[mem=64000]' bash bwa-mem2 index ./data/reference/hg38.fa
```

5. Run **snakefile_fastq2bam.py**

```bash
bsub -o logs_hpc/out_bcl2bam.txt -e logs_hpc/err_bcl2bam.txt -q bio -n 8 -W 1400 -M 64000 -hl -R 'rusage[mem=64000]' snakemake -s snakefile_fastq2bam.py --config pool=POOL-473N --cores 8
```

6. Run **scripts/00_qc.py**

*Note: scripts where submitted to the HPC to freely work on the notebook while the outputs were generated. Manually running the scripts is also an option.*

```bash
bsub -o logs_hpc/out_qc.txt -e logs_hpc/err_qc.txt -q bio -n 1 -W 1400 -M 64000 -hl -R 'rusage[mem=64000]' python scripts/00_qc_after.py
```

7. Run **scripts/01_fragment_lengths.py**

```bash
bsub -o logs_hpc/out_fraglen.txt -e logs_hpc/err_fraglen.txt -q bio -n 1 -W 1400 -M 64000 -hl -R 'rusage[mem=64000]' python scripts/01_fragment_lengths.py
```

8. Run **scripts/02_endmotifs.py**

```bash
bsub -o logs_hpc/out_endmot.txt -e logs_hpc/err_endmot.txt -q bio -n 1 -W 1400 -M 64000 -hl -R 'rusage[mem=64000]' python scripts/02_endmotifs.py
```