{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b23d87a-7273-47f2-97c5-ca37f8c9e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script que implementa FinaleToolkit para análisis fragmentómico\n",
    "# https://github.com/epifluidlab/FinaleToolkit\n",
    "# autora: suarezhs@uoc.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357290dd-0db8-4825-932d-e226bd34ecb6",
   "metadata": {},
   "source": [
    "El pipeline se ha instalado previamente en conda. El environment está disponible en el repositorio (environment.yaml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1260270f-bba9-4b9b-8feb-53e1dbe4a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c bioconda -c conda-forge finaletoolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4504db8-d2b6-4ff5-800a-12ae918596cc",
   "metadata": {},
   "source": [
    "# Importar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3271ff3e-8ae3-4e32-82da-36d25169713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings generales\n",
    "\n",
    "# working directory to root folder\n",
    "import os\n",
    "os.chdir('/mnt/scratch_dir/suarezhs/tfm/bcltofrag')\n",
    "\n",
    "# output directories\n",
    "results_plotdir = 'results/plots'\n",
    "results_filesdir = 'results/files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff247c1d-09ae-4e7d-be0b-64d83cf1eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en terminal\n",
    "#finaletoolkit frag-length-bins \\\n",
    "#   ../data/alignments/POOL-473N/L-25000010_S5.bam \\\n",
    "#   -min 50 \\\n",
    "#   -max 300 \\\n",
    "#   --bin-size 1 \\\n",
    "#   -q 30 \\\n",
    "#   > L-25000010_S5_fraglengths.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a2d868-954a-429d-9936-c78a3ce7e5ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# que hay en el paquete porque no encuento documentacion que no sea\n",
    "# para el command line\n",
    "\n",
    "#import finaletoolkit as ftk\n",
    "#import pkgutil\n",
    "#import importlib\n",
    "\n",
    "#for m in pkgutil.iter_modules(ftk.__path__):\n",
    "#    print(m.name)\n",
    "\n",
    "#submodules = [\"cli\", \"frag\", \"genome\", \"utils\", \"version\"]\n",
    "\n",
    "#for sm in submodules:\n",
    "#    print(\"\\n### Submodule:\", sm)\n",
    "#    mod = importlib.import_module(f\"finaletoolkit.{sm}\")\n",
    "#    print(dir(mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4253281-911f-4087-a865-3491b4b5066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function frag_length_bins in module finaletoolkit.frag._frag_length:\n",
      "\n",
      "frag_length_bins(input_file: 'FragFile', contig: 'str | None' = None, start: 'int | None' = None, stop: 'int | None' = None, min_length: 'int | None' = 0, max_length: 'int | None' = None, bin_size: 'int' = 1, output_file: 'str | None' = None, intersect_policy: 'str' = 'midpoint', quality_threshold: 'int' = 30, summary_stats: 'bool' = False, short_fraction: 'int | None' = None, histogram_path: 'str | None' = None, verbose: 'Union[bool, int]' = False) -> 'tuple[np.ndarray, np.ndarray]'\n",
      "    Takes input_file, computes frag lengths of fragments and returns\n",
      "    two arrays containing bins and counts by size. Optionally prints\n",
      "    data to output as a tab delimited table or histogram.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    input_file : str, AlignmentFile, or TabixFile\n",
      "        BAM, CRAM, or tabix-indexed containing paired-end fragment reads or\n",
      "        its path. pysam wrappers must be opened in read mode.\n",
      "    contig : str, optional\n",
      "        If specified, limits calculations to fragments on this\n",
      "        chromosome/contig. If not specified, lengths are calculated genomewide.\n",
      "    start : int, optional\n",
      "        Left-most coordinate of interval to fetch from. See intersect_policy.\n",
      "        `contig` and `stop` must be specified if a value is given for `start`.\n",
      "    stop : int, optional\n",
      "        Right-most coordinate of interval to fetch from. See intersect_policy.\n",
      "        `contig` and `start` must be specified if a value is given for `stop`.\n",
      "    min_length: int, optional\n",
      "        Specifies shortest fragment length included in array.\n",
      "    max_length: int, optional\n",
      "        Specifies longest fragment length included in array.\n",
      "    bin_size : int, optional\n",
      "        Specify how wide each bin is. If None, will be calculated\n",
      "        automatically.\n",
      "    output_file : str, optional\n",
      "        tsv or tsv.gz file to write results to. Writes to stdout if \"-\".\n",
      "    intersect_policy: str {\"midpoint\", \"any\"}, optional\n",
      "        Specifies what policy is used to include fragments in the\n",
      "        given interval. Default is \"midpoint\". Policies include:\n",
      "        - midpoint: the average of end coordinates of a fragment lies\n",
      "        in the interval.\n",
      "        - any: any part of the fragment is in the interval.\n",
      "    quality_threshold: int, optional\n",
      "        Minimum MAPQ to accept for a fragment to be counted.\n",
      "    summary_stats: bool, optional\n",
      "        When set to true, summary statistics are appended as comments at the\n",
      "        end of the tsv.\n",
      "    short_fraction: int, optional\n",
      "        If specified, the short fraction will be calculated and included in\n",
      "        summary statistics for the tsv and/or histogram.\n",
      "    histogram_path: str, optional\n",
      "        If specified, a simple histograpm will be generated using matplotlib.\n",
      "    workers : int, optional\n",
      "        Number of worker processes.\n",
      "    verbose : bool, optional\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    bins : ndarray\n",
      "    counts : ndarray\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#help(frag.frag_length_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491cba80-f339-4bd0-beb6-4fab654f559a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L-25000063_S1\n",
      "L-25000080_S8\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from finaletoolkit.frag import frag_length_bins \n",
    "for filename in glob.glob(\"../data/alignments/POOL-527N/*.markdup.bam\"):\n",
    "    #print(os.path.basename(filename)) # basename extrae filename del filename\n",
    "    # guardo samplename quitando la extension\n",
    "    samplename = os.path.basename(filename).replace(\".markdup.bam\", \"\")\n",
    "    print(samplename)\n",
    "    frag_length_bins(input_file=filename,\n",
    "                     bin_size=1,\n",
    "                     min_length=50, \n",
    "                     max_length=300,\n",
    "                     quality_threshold=30,\n",
    "                     output_file=os.path.join(results_filesdir, samplename + \".tsv\"),\n",
    "                     histogram_path=os.path.join(results_plotdir, samplename + \".png\")\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b678f65-c712-4526-94eb-d55b77615b42",
   "metadata": {},
   "source": [
    "# TO-DO\n",
    "\n",
    "## Procesado de datos:\n",
    "- [x] Run POOL-527N\n",
    "- [ ] Running: POOL-473\n",
    "- [ ] Run las demas\n",
    "\n",
    "## Resultados:\n",
    "- [ ] (50%) Automatizar generar .tsv y visualizaciones (primero decidir cuales son importantes)  \n",
    "- [ ] Generar tsv file sin filtrar duplicados y filtrando duplicados. Histogram overlap.\n",
    "\n",
    "\n",
    "## Otros:\n",
    "- [ ] completar snakefile con regla bcl2fastq\n",
    "- [ ] repetir snakemake usando tool Agilent para sacar fastq con UMI (3ra read) y marcar duplicados con picard UMI-aware thingy (ver mail Ivan)\n",
    "- [ ] end motifs\n",
    "- [ ] actualizar readme con como instalar y hacer el pipeline desde Illumina -> notebook? outputs?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fragmentomics)",
   "language": "python",
   "name": "fragmentomics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
